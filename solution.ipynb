{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "solution (3).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "neptune": {
      "notebookId": "edda6c46-19ea-4f2f-ba3a-c25485380ab2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gaussiandra/AI-21-qual/blob/main/solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGm6XtTLsyHI"
      },
      "source": [
        "!pip install neptune-notebooks\n",
        "!jupyter nbextension enable --py neptune-notebooks\n",
        "!pip install ipywidgets\n",
        "!jupyter nbextension enable --py widgetsnbextension"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yad9UNcG1b-w",
        "scrolled": false
      },
      "source": [
        "!pip install transformers\n",
        "!pip install catalyst\n",
        "!pip install neptune-client"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vR583H9Sirj",
        "outputId": "e1be7424-cb9b-4e2e-fa77-aabcd191dfbb"
      },
      "source": [
        "!free -m\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              total        used        free      shared  buff/cache   available\n",
            "Mem:        1546833       78117       87587         733     1381128     1461338\n",
            "Swap:             0           0           0\n",
            "Sun Feb 28 17:06:28 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.165.02   Driver Version: 418.165.02   CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM3...  On   | 00000000:5E:00.0 Off |                    0 |\n",
            "| N/A   49C    P0    51W / 350W |      0MiB / 32480MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IslBv6JkWC7c"
      },
      "source": [
        "global_path = '/home/jovyan/AI_21/'\n",
        "\n",
        "experiment_params = {\n",
        "    'MODEL_NAME': 'DeepPavlov/rubert-base-cased',\n",
        "    'MAX_LEN': 512,\n",
        "    'EFFECTIVE_BATCH_SIZE': 16,\n",
        "    'BATCH_SIZE': 16,\n",
        "    'RANDOM_SEED': 665,\n",
        "    'NUM_CLASSES': 2,\n",
        "    'LEARNING_RATE': 5e-5,\n",
        "    'CHANGE_QUESTION_PROBA': 0.05,\n",
        "    'CHANGE_ANSWER_PROBA': 0.05,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Os9oln5XWio9"
      },
      "source": [
        "import json\n",
        "import os\n",
        "import sys\n",
        "import re\n",
        "import random\n",
        "from tqdm.auto import tqdm\n",
        "from collections import defaultdict\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import neptune\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "from catalyst.dl import SupervisedRunner\n",
        "from catalyst.core.callback import Callback, CallbackNode, CallbackOrder\n",
        "from catalyst.utils import prepare_cudnn, set_global_seed\n",
        "from catalyst import utils, dl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLiJ3CGjWcav"
      },
      "source": [
        "raw_train = [json.loads(s) for s in open(global_path+'data/train.jsonl')]\n",
        "raw_test = [json.loads(s) for s in open(global_path+'data/test.jsonl')]\n",
        "raw_val = [json.loads(s) for s in open(global_path+'data/val.jsonl')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tQqdA8_YTiO"
      },
      "source": [
        "### Statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqYkqMPpva7r",
        "outputId": "d3685abc-5ae6-4796-c6d0-2ac60b0be9d5"
      },
      "source": [
        "len(raw_train), len(raw_test), len(raw_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500, 322, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mHodlII8diZ",
        "outputId": "ccc646e4-3f02-46c0-faf0-b58ae8742583"
      },
      "source": [
        "raw_train[43]['passage']['text']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"(1) Лидер незарегистрированной партии \"Другая Россия\" Эдуард Лимонов обратился в Конституционный суд РФ с жалобой на новый закон о митингах. (2) Об этом 9 октября сообщает агентство \"Интерфакс\". (3) \"У меня есть слабая надежда. (4) Закон о митингах противоречит Конституции\", - заявил Лимонов. (5) По его мнению, среди неконституционных пунктов закона - запрет на организацию митингов людьми, которые более двух раз привлекались к административной ответственности за нарушение правил предвыборной агитации, неповиновение полиции, хулиганство, блокирование движения транспорта или производство экстремистских материалов. (6) Закон о митингах был применён лично против Лимонова. (7) Его оштрафовали на 12 тысяч рублей за акцию на Триумфальной площади 31 июля. (8) Федеральный закон \"О собраниях, митингах, демонстрациях, шествиях и пикетированиях\" вступил в силу 9 июня 2012 года. (9) О намерении оспорить закон в КС практически сразу объявили думские фракции \"Справедливой России\" и КПРФ. (10) В итоге запрос в КС направили только эсеры. (11) Лидер фракции Сергей Миронов заявил о \"разделении обязанностей\" между СР и КПРФ. (12) \"С коммунистами мы уже де-факто в долговременном союзе. (13) Взять, к примеру, наши запросы в Конституционный суд: мы - по закону о митингах, они - по закону о выборах губернаторов\", - пояснил он. (14) Об ответе суда на запрос пока не сообщалось.\"'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUglseAvW7v7",
        "outputId": "f009d5bc-8463-4357-e2b7-db915c7feab4"
      },
      "source": [
        "n_questions, n_answers, n_corrects = 0, 0, 0\n",
        "texts_lens = []\n",
        "for cur_q in raw_train:\n",
        "    texts_lens.append(len(cur_q['passage']['text']))\n",
        "    for question in cur_q['passage']['questions']:\n",
        "        n_questions += 1\n",
        "        n_answers += len(question['answers'])\n",
        "        n_corrects += sum(i['label'] for i in question['answers'])\n",
        "print(n_questions, n_answers, n_answers / n_corrects)\n",
        "print(np.mean(texts_lens))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2897 11950 2.220364176885916\n",
            "1380.538\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTMkte7ZmN71"
      },
      "source": [
        "### Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pSvJ5UWYXts"
      },
      "source": [
        "class QADataset(Dataset):\n",
        "    def __init__(\n",
        "        self, \n",
        "        samples, \n",
        "        model_name, \n",
        "        max_len,\n",
        "        **kwargs\n",
        "    ):\n",
        "        self.model_name = model_name\n",
        "        self.max_len = max_len\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "        self.kwargs = kwargs\n",
        "\n",
        "        # text, question, answer\n",
        "        self.raw_triplets = []\n",
        "        self.labels = []\n",
        "\n",
        "        for sample in samples:\n",
        "            text = sample['passage']['text']\n",
        "            text = re.sub('\\(\\d+\\)', '', text)\n",
        "\n",
        "            for task in sample['passage']['questions']:\n",
        "                question = task['question']\n",
        "                for answer_info in task['answers']:\n",
        "                    answer = answer_info['text']\n",
        "                    if 'label' in answer_info:\n",
        "                        label = answer_info['label']\n",
        "                        self.labels.append(label)\n",
        "                    self.raw_triplets.append([text, question, answer])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.raw_triplets)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        text, question, answer = self.raw_triplets[index]\n",
        "\n",
        "        is_augmented_sample = False\n",
        "        if ('CHANGE_QUESTION_PROBA' in self.kwargs and\n",
        "            'CHANGE_ANSWER_PROBA' in self.kwargs):\n",
        "            if random.random() <= self.kwargs['CHANGE_QUESTION_PROBA']:\n",
        "                question = random.choice(self.raw_triplets)[1]\n",
        "                is_augmented_sample = True\n",
        "\n",
        "            if random.random() <= self.kwargs['CHANGE_ANSWER_PROBA']:\n",
        "                answer = random.choice(self.raw_triplets)[2]\n",
        "                is_augmented_sample = True\n",
        "\n",
        "        tokenization = self.tokenizer([text, question, answer])\n",
        "\n",
        "        remain_text_part = (\n",
        "            self.max_len - \n",
        "            len(tokenization['input_ids'][1][1:]) - # question\n",
        "            len(tokenization['input_ids'][2][1:])   # answer\n",
        "        )\n",
        "        remain_text_part = min(\n",
        "            remain_text_part, \n",
        "            len(tokenization['input_ids'][0])\n",
        "        )\n",
        "        assert remain_text_part > 0\n",
        "\n",
        "        # concatenate tokenized triplets\n",
        "        tokenization['input_ids'] = (\n",
        "            tokenization['input_ids'][0][:remain_text_part - 1] +\n",
        "            [self.tokenizer.sep_token_id] +\n",
        "            tokenization['input_ids'][1][1:] +\n",
        "            tokenization['input_ids'][2][1:]\n",
        "        )\n",
        "        if 'token_type_ids' in tokenization:\n",
        "            tokenization['token_type_ids'] = (\n",
        "                tokenization['token_type_ids'][0][:remain_text_part] + \n",
        "                [1] * len(tokenization['token_type_ids'][1][1:]) +\n",
        "                [1] * len(tokenization['token_type_ids'][2][1:])\n",
        "            )\n",
        "            assert len(tokenization['input_ids']) == len(tokenization['token_type_ids'])\n",
        "        tokenization['attention_mask'] = [1] * len(tokenization['input_ids'])\n",
        "        assert len(tokenization['input_ids']) == len(tokenization['attention_mask'])\n",
        "\n",
        "        for k, v in tokenization.items():\n",
        "            tokenization[k] = torch.tensor(np.pad(\n",
        "                v,\n",
        "                (0, self.max_len - len(v)), \n",
        "                constant_values=self.tokenizer.pad_token_id\n",
        "            ))\n",
        "            assert tokenization[k].shape[0] == self.max_len\n",
        "\n",
        "        if self.labels:\n",
        "            if is_augmented_sample:\n",
        "                tokenization['targets'] = torch.tensor(0)\n",
        "            else:\n",
        "                tokenization['targets'] = torch.tensor(self.labels[index])\n",
        "\n",
        "        return tokenization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IPJXI_2tdx2",
        "scrolled": true
      },
      "source": [
        "train_qa_dataset = QADataset(\n",
        "    samples=raw_train,\n",
        "    model_name=experiment_params['MODEL_NAME'], \n",
        "    max_len=experiment_params['MAX_LEN'],\n",
        "    CHANGE_QUESTION_PROBA=experiment_params['CHANGE_QUESTION_PROBA'],\n",
        "    CHANGE_ANSWER_PROBA=experiment_params['CHANGE_ANSWER_PROBA'],\n",
        ")\n",
        "val_qa_dataset = QADataset(\n",
        "    samples=raw_val, \n",
        "    model_name=experiment_params['MODEL_NAME'], \n",
        "    max_len=experiment_params['MAX_LEN'],\n",
        "    CHANGE_QUESTION_PROBA=experiment_params['CHANGE_QUESTION_PROBA'],\n",
        "    CHANGE_ANSWER_PROBA=experiment_params['CHANGE_ANSWER_PROBA'],\n",
        ")\n",
        "test_qa_dataset = QADataset(\n",
        "    samples=raw_test, \n",
        "    model_name=experiment_params['MODEL_NAME'], \n",
        "    max_len=experiment_params['MAX_LEN'],\n",
        "    CHANGE_QUESTION_PROBA=experiment_params['CHANGE_QUESTION_PROBA'],\n",
        "    CHANGE_ANSWER_PROBA=experiment_params['CHANGE_ANSWER_PROBA'],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1z59fc4tAj3"
      },
      "source": [
        "train_val_dataloaders = {\n",
        "    'train': DataLoader(\n",
        "        dataset=train_qa_dataset,\n",
        "        batch_size=experiment_params['BATCH_SIZE'], \n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        pin_memory=True\n",
        "    ),\n",
        "    'valid': DataLoader(\n",
        "        dataset=val_qa_dataset, \n",
        "        batch_size=experiment_params['BATCH_SIZE'], \n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=False,\n",
        "    )\n",
        "}\n",
        "test_dataloader = {\n",
        "    'infer': DataLoader(\n",
        "        dataset=test_qa_dataset, \n",
        "        batch_size=experiment_params['BATCH_SIZE'], \n",
        "        shuffle=False,\n",
        "    )\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9Cpfbmlnf0w"
      },
      "source": [
        "### Model and training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leccRe6ab273"
      },
      "source": [
        "class QAModel(nn.Module):\n",
        "    def __init__(self, model_name, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        self.model = AutoModel.from_pretrained(model_name)\n",
        "        self.linear = nn.Linear(self.model.config.hidden_size, num_classes)\n",
        "        self.dropout = nn.Dropout(0.15)\n",
        "\n",
        "    def forward(self, kwargs):\n",
        "        x = self.model(**kwargs).pooler_output\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6ORnOpc9x5C"
      },
      "source": [
        "model = QAModel(experiment_params['MODEL_NAME'], experiment_params['NUM_CLASSES'])\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=experiment_params['LEARNING_RATE'], amsgrad=True)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, factor=0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRHxRJN6OiMW"
      },
      "source": [
        "for n, p in model.named_parameters():\n",
        "    if any([n.startswith(s) for s in [\n",
        "        'model.encoder.layer.22',\n",
        "        'model.encoder.layer.23', \n",
        "        'model.pooler', \n",
        "        'linear'\n",
        "    ]]):\n",
        "        p.requires_grad = True\n",
        "    else:\n",
        "        p.requires_grad = False\n",
        "\n",
        "\n",
        "class FullUnreezeCallback(Callback):\n",
        "    def __init__(self, batches_to_unfreeze):\n",
        "        super().__init__(order=CallbackOrder.Metric + 1, node=CallbackNode.All)\n",
        "\n",
        "        self.batches_to_unfreeze = batches_to_unfreeze\n",
        "        self.cur_iteration = 0\n",
        "        self.is_unfrozen = False\n",
        "\n",
        "    def on_batch_end(self, runner):\n",
        "        if runner.is_train_loader:\n",
        "            self.cur_iteration += 1\n",
        "            if (self.cur_iteration >= self.batches_to_unfreeze and \n",
        "                not self.is_unfrozen):\n",
        "                for p in runner.model.parameters():\n",
        "                    p.requires_grad = True\n",
        "\n",
        "                self.is_unfrozen = True\n",
        "                print('Model was unfrozen.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6dw-yhmsyHW",
        "outputId": "b8f7f844-2baf-4371-91aa-48cf440171b5"
      },
      "source": [
        "neptune_logger = dl.NeptuneLogger(\n",
        "    api_token='-',\n",
        "    project_name='gaussiandra/ai21-2-test',\n",
        "    offline_mode=False,\n",
        "    name='example',\n",
        "    params=experiment_params,\n",
        "    tags=['test'],\n",
        "    upload_source_files=['*.ipynb'], \n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://ui.neptune.ai/gaussiandra/ai21-2-test/e/AIT-3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMAsO_BVHLmw"
      },
      "source": [
        "set_global_seed(experiment_params['RANDOM_SEED'])\n",
        "prepare_cudnn(deterministic=True, benchmark=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GhMrVxfD9xl"
      },
      "source": [
        "logdir = global_path+'logs/test02'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNvi5_7a_4Ja"
      },
      "source": [
        "class CustomRunner(dl.Runner):\n",
        "    def predict_batch(self, batch):\n",
        "        x = dict(batch)\n",
        "        del x['targets']\n",
        "\n",
        "        return self.model(x)\n",
        "    \n",
        "    def _handle_batch(self, batch):\n",
        "        x = dict(batch)\n",
        "        del x['targets']\n",
        "        y = batch['targets']\n",
        "\n",
        "        logits = self.model(x)\n",
        "\n",
        "        self.state.input = {\"features\": x, \"targets\": y}\n",
        "        self.state.output = {\"logits\": logits}\n",
        "\n",
        "runner = CustomRunner()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gi5bR_IJkZEM"
      },
      "source": [
        "runner.train(\n",
        "    model=model,\n",
        "    criterion=nn.CrossEntropyLoss(),\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    loaders=train_val_dataloaders,\n",
        "    callbacks=[\n",
        "        dl.AccuracyCallback(num_classes=experiment_params['NUM_CLASSES']),\n",
        "        dl.OptimizerCallback(\n",
        "            accumulation_steps=(\n",
        "                experiment_params['EFFECTIVE_BATCH_SIZE'] //\n",
        "                experiment_params['BATCH_SIZE']\n",
        "            ),\n",
        "            use_fast_zero_grad=True\n",
        "        ),\n",
        "        dl.F1ScoreCallback(),\n",
        "        dl.CheckpointCallback(\n",
        "            save_n_best=0,\n",
        "            #resume=global_path+'logs/test28/checkpoints/last_full.pth'\n",
        "        ),\n",
        "        #FullUnreezeCallback(50),\n",
        "        dl.CriterionCallback(),\n",
        "        dl.SchedulerCallback(reduced_metric='loss'),\n",
        "        dl.EarlyStoppingCallback(3),\n",
        "        neptune_logger\n",
        "    ],\n",
        "    logdir=logdir,\n",
        "    num_epochs=3,\n",
        "    verbose=True,\n",
        "    fp16=True,\n",
        "    timeit=False,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mRI0Agp-HFB"
      },
      "source": [
        "### Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m-Npp1_rwK0"
      },
      "source": [
        "runner.infer(\n",
        "    model=model,\n",
        "    loaders=test_dataloader,\n",
        "    callbacks=[InferCallback()],\n",
        "    verbose=True,\n",
        "    resume='/content/drive/MyDrive/ML/AI 21/logs/test14/checkpoints/train.2.pth'\n",
        ")\n",
        "assert len(runner.callbacks[0].predictions['logits']) == 7614"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiEvozcZzayY"
      },
      "source": [
        "for s, sample in enumerate(submit_example):\n",
        "    for t, task in enumerate(sample['passage']['questions']):\n",
        "        for a, answer_info in enumerate(task['answers']):           \n",
        "            submit_location = submit_example[s]['passage']['questions'][t]['answers'][a]\n",
        "            final_answer = np.argmax(runner.callbacks[0].predictions['logits'][answer_info['idx']])\n",
        "\n",
        "            submit_location['label'] = int(final_answer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQHvuB8c4X4I"
      },
      "source": [
        "json_lines = [json.dumps(s) for s in submit_example]\n",
        "open(global_path+'data/submit.jsonl', 'w').write('\\n'.join(json_lines))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
### Описание
Отборочный контест на олимпиаду НТИ по искусственному интеллекту на датасете MuSeRC, который представляет собой задачу reading comprehension, где чтобы ответить на вопрос, необходима информация из нескольких предложений. Дается текст, вопрос к нему и варианты ответов. На вопрос невозможно ответить не произведя операции причинно-следственных связей.

##### Пример данных для обучения
![Снимок](https://user-images.githubusercontent.com/34653515/111829934-63101080-88fe-11eb-964c-e51c980b0447.PNG)

### Применённый подход
* Задача была сведена к бинарной классификации с помощью **Rubert от DeepPavlov из Huggingface**. 
* Для ответа на вопрос использовались тройки, разделённые `[SEP]` токеном и состоящие из исходного текста, вопроса и предлагаемого ответа.
* Из всего текста была удалена нумерация.
* Использовалась аугментация с рандомной заменой вопроса или предлагаемого ответа.
* Вначале файнтюнинга последние слои сети замораживались.
* В проекте использовались **PyTorch** и **Catalyst** для обучения модели, **Neptune AI** для контроля экспериментов.
* Сеть училась с помощью оптимизатора **AdamW** и **ReduceLROnPlateau** планировщика в **FP16** режиме.
* *Была также идея давать сети возможность смотреть сразу на все варианты ответов, как например делается в этой [статье](https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/viewFile/16331/16177), но с использованием attention транформера. Задумка значительно повышала точность на тренировочных данных, но не давала совершенно никакого эффекта на тестовых, поэтому от неё решено было отказаться.*

##### По итогу соревнования такой подход давал 0.739 по F1 и 28/184 место на приватной части лидерборда, но вполне реально было выжать и больше, используя данные с валидации, Large версию модели и блендинг.
